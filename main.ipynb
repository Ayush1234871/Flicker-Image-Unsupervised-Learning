{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da951ef6",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d37070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f3e65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd9fdd",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17688063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output.csv\") \n",
    "comments = df['comment'].dropna().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181830d5",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9b26831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = text.split()\n",
    "    return ' '.join([w for w in words if w not in stop_words])\n",
    "\n",
    "cleaned = comments.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3d21f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = vectorizer.fit_transform(cleaned)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_lsa = svd.fit_transform(X_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0509e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhay\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=20, batch_size=1000, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.3, min_samples=5, metric='cosine', n_jobs=-1)\n",
    "dbscan_labels = dbscan.fit_predict(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce4ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000  \n",
    "agg = AgglomerativeClustering(n_clusters=20)\n",
    "agg_labels_partial = agg.fit_predict(X_lsa[:sample_size])\n",
    "agg_labels = np.full(len(X_lsa), -1)\n",
    "agg_labels[:sample_size] = agg_labels_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777995aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_labels = set(kmeans_labels)\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    mask = kmeans_labels == label\n",
    "    plt.scatter(X_2d[mask, 0], X_2d[mask, 1], s=10, color=color, label=f'Cluster {label}')\n",
    "\n",
    "plt.title(\"KMeans Clustering (2D Projection using SVD)\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend(loc='best', markerscale=2)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c45700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svd_2d = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_2d = svd_2d.fit_transform(X_tfidf)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_labels = set(dbscan_labels)\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    mask = dbscan_labels == label\n",
    "    plt.scatter(X_2d[mask, 0], X_2d[mask, 1], s=10, color=color, label=f'Cluster {label}' if label != -1 else \"Noise\")\n",
    "\n",
    "plt.title(\"DBSCAN Clustering (2D Projection using SVD)\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend(loc='best', markerscale=2)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = []\n",
    "for i in range(len(comments)):\n",
    "    votes = [kmeans_labels[i], dbscan_labels[i], agg_labels[i]]\n",
    "    filtered_votes = [v for v in votes if v != -1]\n",
    "    label = Counter(filtered_votes).most_common(1)[0][0] if filtered_votes else -1\n",
    "    final_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7265b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: child, small, young, woman, holding\n",
      "Cluster 1: jacket, man, wearing, black, blue\n",
      "Cluster 2: shirt, man, blue, wearing, white\n",
      "Cluster 3: crowd, people, front, man, large\n",
      "Cluster 4: playing, guitar, man, two, game\n",
      "Cluster 5: man, person, wearing, sitting, white\n",
      "Cluster 6: two, men, women, one, girls\n",
      "Cluster 7: people, two, three, walking, sitting\n",
      "Cluster 8: water, body, man, dog, boat\n",
      "Cluster 9: boy, young, little, shirt, blue\n",
      "Cluster 10: group, people, men, standing, large\n",
      "Cluster 11: working, man, men, construction, two\n",
      "Cluster 12: street, walking, man, city, people\n",
      "Cluster 13: woman, man, wearing, sitting, black\n",
      "Cluster 14: children, two, playing, group, three\n",
      "Cluster 15: jumping, dog, air, boy, man\n",
      "Cluster 16: girl, little, young, pink, wearing\n",
      "Cluster 17: dogs, two, running, grass, snow\n",
      "Cluster 18: holding, man, woman, wearing, baby\n",
      "Cluster 19: dog, brown, black, running, white\n"
     ]
    }
   ],
   "source": [
    "def top_terms_per_cluster(X_tfidf, labels, vectorizer, top_n=5):\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    for cluster_num in np.unique(labels):\n",
    "        if cluster_num == -1:\n",
    "            continue \n",
    "        cluster_indices = np.where(labels == cluster_num)[0]\n",
    "        mean_tfidf = X_tfidf[cluster_indices].mean(axis=0).A1\n",
    "        top_terms = terms[mean_tfidf.argsort()[::-1][:top_n]]\n",
    "        print(f\"Cluster {cluster_num}: {', '.join(top_terms)}\")\n",
    "\n",
    "top_terms_per_cluster(X_tfidf, kmeans_labels, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb618fb",
   "metadata": {},
   "source": [
    "Saving Output in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab435ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with stemming complete. Output saved to 'clustered_output_stemmed.csv'\n"
     ]
    }
   ],
   "source": [
    "df['KMeans_Label'] = kmeans_labels\n",
    "df['DBSCAN_Label'] = dbscan_labels\n",
    "df['Agglomerative_Label'] = agg_labels\n",
    "df['Final_Label'] = final_labels\n",
    "\n",
    "df.to_csv(\"clustered_output11.csv\", index=False)\n",
    "print(\"Clustering with stemming complete. Output saved to 'clustered_output_stemmed.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff0e25",
   "metadata": {},
   "source": [
    "Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c165a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "models = {\n",
    "    'vectorizer': vectorizer,\n",
    "    'svd': svd,\n",
    "    'kmeans': kmeans,\n",
    "    'dbscan': dbscan,\n",
    "    'agg': agg\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a90c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models and vectorizer saved to 'clustering_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open('clustering_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "\n",
    "print(\"All models and vectorizer saved to 'clustering_pipeline.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
